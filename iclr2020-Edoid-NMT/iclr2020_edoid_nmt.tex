
\documentclass{article} % For LaTeX2e
\usepackage{iclr2020_conference,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage{hyperref}
\usepackage{url}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{multirow}

\def\UrlBreaks{\do\/\do-}

\title{Towards Neural Machine Translation \\ for Edoid Languages}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

\author{Iroro Fred \d{\`O}n\d{\`o}m\d{\`e} Orife \\
Niger-Volta Language Technologies Institute\\
\texttt{iroro@alumni.cmu.edu} \\
%\And
%Dr. John N. Orife\\
%Indiana University of Pennsylvania, \\
%\texttt{jorife@iup.edu} \\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

%\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}


\maketitle

%\begin{abstract}
%Many Nigerian languages have   Using the new JW300 public dataset, we trained and evaluated baseline translation models for four widely spoken languages: \d{\`E}d{\'o}, \d{\`E}s{\'a}n, Urhobo and Isoko. Trained models, code and datasets have been open-sourced to advance future research efforts on Edoid language technology.\\

%Given the empowering potential of language technology, we investigate the feasibility of Neural Machine Translation (NMT) for speakers of Edoid languages of Southern Nigeria.
%\end{abstract}

\section{Introduction}

% How language inequality came about
Many of the over 500 languages are spoken in Nigeria today have relinquished their previous prestige and purpose in modern society to English and Nigerian Pidgin, notably amongst the younger generations. Unlike numerous East and South Asian societies, which preserved the socio-linguistic status of their indigenous languages under colonial rule, Nigerian communities with primarily oral traditions have been the most susceptible to language endangerment \citep{rolle2013phonetics, omo2004esan}.

% How language inequality affects people and indigenous language research
For tens of millions of speakers, language inequalities manifest themselves as unequal access to information, communications, health care, security along with attenuated participation in political and civic life. These inequities are further exacerbated in a technological age, where only the most highly resourced (i.e. colonial) languages become the milieu for economic advancement \citep{odojelanguage, awobuluyi201626, ganagana2019contrastive}. Finally, there have been practical and technical challenges in language technology for indigenous languages like orthographic standardizations and consistent diacritic representation (Unicode) in electronic media and across device types. 

% How can NMT help?
For almost-extinct languages, machine translation offers hope for language documentation and preservation. For speakers of minority Nigerian languages, it can facilitate good governance, national development and offers a path for technological, economic, social and political participation and empowerment to those with unequal access \citep{odoje201612, odojelanguage}. Using the new JW300 public dataset, we trained and evaluated baseline Neural Machine Translation (NMT) models for four of the widely spoken Edoid languages: \d{\`E}d{\'o}, \d{\`E}s{\'a}n, Urhobo and Isoko. 

% based on economic status, demography, location and language
%From a research vantage, these languages have been labelled ``low resource" due to the scarcity of academic research, online-datasets, funding and interest, due to perceptions about the prestige and utility of these languages in contemporary African life  
% Among other factors, the scarcity of highly esteemed works of literary scholarship has worked to devalue indigenous languages, making them susceptible to being replaced by other languages of power and status \citep{awobuluyi201626}. 

\subsection{Edoid Languages}

% Population
% Edo: 2.5M \\
% Esan: 500k \\
% Urhobo: 500k - 1.5M/2M
% Isoko: 658,000 

Belonging to the eastern sub-branch of the Volta-Niger family within the Niger-Congo phylum, and spoken by approximately 5 million people, the Edoid languages of Southern Nigeria (Edo and Delta State) comprise over two dozen so-called ``minority" languages. The term \emph{Edoid} stems from \d{\`E}d{\'o}, the most broadly spoken member langauge and the language of the famed Kingdom of Benin. \d{\`E}d{\'o}, \d{\`E}s{\'a}n are members of the North-Central branch while Urhobo and Isoko belong to the South-Western family \citep{wiki_Edoid}. These languages were selected based on the availability of text and because they are the most widely spoken.

Edoid langauges generally employ the SVO constituent order type, open syllable systems with very few consonant clusters. Each language has at least two basic tone levels, high (H) and low (L) with kinetic, downstepped or contour tones variously utilized. As tone patterns serve different lexical and grammatical functions, ``the phonetic and phonological implementation of this system is in fact complex and difficult to pin down" \citep{rolle2013phonetics, ogie2009multi, adeniyi2010tone, ilolo2013vowel}. Finally, nasalisation is very common for both vowels and consonants \citep{Elugbe_1989, isoko_phonetics, ikoyo2018phonetic}. 

% urban  centers  of  Urhoboland  such  as  Effurun,  Sapele,  Ughelli,  and  Warri  do  not  use  and/or  speak  the  language. 
%For these reasons, speaker populatioin greater than acutally speakers, and low usage in the young, we consider one should consider the Edoid languages as highly endangered, inspite a large speaker population \citep{rolle2013phonetics}.
%A language can only resist death/extinction if it is able to move from the status of oracy to awritten status. Okojie (1994) 

Within Nigeria there is scholarship on rule, phrase and statistical machine translation systems for majority tongues of Yor{\`u}b{\'a}, Igbo and Hausa \citep{odojelanguage}. The present study is the first work known to the authors done in computational linguistics for any of the Edoid langauges, specifically for machine translation.


\section{Methodology}
\label{methods}
We first built baseline models using the Transformer architecture, the dominant modeling approach for NMT. The Transformer uses an encoder-decoder structure with stacked multi-head self-attention and fully connected layers \citep{NIPS2017_7181}. Given the performance Byte Pair Encoding subword tokenization for low-resourced South African languages, we trained baseline models based on 

 contrast the performance of a baseline Transfomer NMT model across the four languages under study. We examining the effect of word-level versus subword-level tokenization.

\subsection{Dataset}
The recently released JW300 dataset is a large-scale, parallel corpus for Machine Translation (MT) comprising more than three hundred languages of which 101 are African \citep{agic-vulic-2019-jw300}. English-\{\d{\`E}d{\'o}, \d{\`E}s{\'a}n, Urhobo, Isoko\} token pairs cardinality is itemized in Appendix Table~\ref{results}. JW300 text is drawn from a number of online blogs, news and contemporary religious magazines by Jehovah's Witnesses (JW).

\subsection{Models}
The open-source, Python 3 machine translation toolkit \texttt{JoeyNMT} was used to train models based on the Transformer architecture, the dominant modeling approach for NMT. The Transformer uses an encoder-decoder structure with stacked multi-head self-attention and fully connected layers \citep{JoeyNMT, NIPS2017_7181}. 

Our training hardware was the standard free-tier configuration on Google Colaboratory, a single core 2.30GHz Xeon CPU instance and a Tesla K80 GPU with 2496 CUDA cores and 11.4GB RAM. Training the various models took place over the course of a few days, as experiments were repeated for tokenization experiments.

\section{Results}
\label{results}



\subsection{Qualitative}

% Dad's view on the concepts 
Unsuprisingly, for Urhobo and Isoko which are much better resourced, the BLEU scores are generally correlated with the translation quality when reviewed by L1 speakers. For example, for Urhobo this translation captures much. Additional examples are listed in the Appendix.

\subsection{Error Analysis}
While performing error analyses on the model predictions, we observed predictions that included  dataset requires more preprocessing to remove scriptural chapter and verse text.  chapters\/verse names and figures. This will make the model more generally useful outside of religious text translations.

\section{Future Work and Conclusions}
Fertile avenues for future work include acquiring more data, hyper-parameter optimization and experiments with Backtranslation, different tokenization approaches as well as specific consideration of linguistic knowledge. For example, the analytic nature of Edoid languages and low morpheme-per-word ratio might inform a novel tokenization approach.

 The objective of this paper was to report preliminary efforts to assist translators and the lay-person alike, working in Edoid languages. We hope to bootstrap the development and sustenance of scholarly and literary traditions, beyond religious texts. By making our models and code broadly accessible as open-source projects, we hope to energize academic and industry interest broader language technology for socio-linguistic and economic empowerment.`
 
% Thee include social justice by addressing an aspect of technological language inequality, language perservation and by establishing baselines and from which to build on. Given the comparatively low (Oladele Awobuluyi) litearay traditions but the very strong oral traditions, foundational language technologies based on good clean text, like language and translation models are just the start, but very important precusor to speech interfaces. Imagine a world in which a culture rooted in a strong oral tradition can make use of Speech-to-Speech interfaces, speaking and being spoken to idiomatically. This is where the future of African langauge technology lies and mahcine translation and good clean datasets are the core.   
% 


% Applications to film and cinema technology to automatically subtitle and translate Edoid language films.

% paint a future where robust speech-to-speech interfaces kick ass and allow everyone to speak freely


All public-domain datasets referenced in this work are available on GitHub.\footnote{\url{https://github.com/Niger-Volta-LTI}}

\subsubsection*{Acknowledgments}
The authors thank Dr. Ajovi B. Scott-Emuakpor, MD and Dr. John Nevboyeri Orife for their encouragement, support and qualitative translations.

\bibliography{iclr2020_conference}
\bibliographystyle{iclr2020_conference}

\clearpage

\appendix
\section{Appendix}

\begin{table}[h]
\caption{Per-language BLEU scores by BPE or word-level tokenization}
\label{results}
\begin{center}
\begin{tabular}{c@{\qquad}ccc@{\qquad}ccc}
  \toprule
  \multirow{2}{*}{\raisebox{-\heavyrulewidth}{\textbf{Lang}}} & \multicolumn{2}{c}{\textbf{BPE}} & \multicolumn{2}{c}{\textbf{Word}} & \multirow{2}{*}{\raisebox{-\heavyrulewidth}{\textbf{Tokens}}} & \multirow{2}{*}{\raisebox{-\heavyrulewidth}{\textbf{Sentences}}}
  	 \\
  \cmidrule{2-5}
  & dev & test & dev & test \\
  \midrule
  \d{\`E}d{\'o}  & 7.92 & 12.49 & 5.99 & 8.24 &  229,307 & 10,188 \\
  \d{\`E}s{\'a}n & 4.94 & 6.25 & 3.39 & 5.30 & 87,025 & 4,128 \\
    \midrule
  Urhobo  & 15.91 & 28.82 & 11.80 & 22.39 & 519,981 & 214,546 \\
  Isoko   & 32.58 & 38.05 & 32.38 & 38.91 & 4,824,998 & 25,610 \\
  \bottomrule
  \end{tabular}
\end{center}
\end{table}

\begin{table}[h]
\caption{Example Translations}
\label{results}
\begin{center}
  \begin{tabular}{ll}
  	\toprule
     \textbf{\d{\`E}d{\'o}}  & \\
     \toprule
     \toprule
	 Source: &    Still , words of apology are a strong force toward making peace \\
	 Reference: & Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ \\
	 Prediction: & Ghele na , eme unu - uwou yọ ẹgba ologbo nọ ma re ro ru udhedhẹ \\
     \midrule
	 Source:  &   We can even ask God to ‘ create in us a pure heart \\
	 Reference: &  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo \\
	 Prediction: & Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo \\ 
     \\
  	 \toprule
     \textbf{\d{\`E}s{\'a}n}  & \\
     \toprule
     \toprule
	 Source: &    Still , words of apology are a strong force toward making peace \\
	 Reference: & Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ \\
	 Prediction: & Ghele na , eme unu - uwou yọ ẹgba ologbo nọ ma re ro ru udhedhẹ \\
     \midrule
	 Source:  &   We can even ask God to ‘ create in us a pure heart \\
	 Reference: &  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo \\
	 Prediction: & Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo \\ 
	\\
	\toprule
     \textbf{Urhobo}  & \\
    \toprule
    \toprule
	 Source: &    Still , words of apology are a strong force toward making peace \\
	 Reference: & Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ \\
	 Prediction: & Ghele na , eme unu - uwou yọ ẹgba ologbo nọ ma re ro ru udhedhẹ \\
     \midrule
	 Source:  &   We can even ask God to ‘ create in us a pure heart \\
	 Reference: &  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo \\
	 Prediction: & Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo \\ 
     \\
     \toprule
     \textbf{Isoko}  & \\
    \toprule
    \toprule
	 Source: &    Still , words of apology are a strong force toward making peace \\
	 Reference: & Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ \\
	 Prediction: & Ghele na , eme unu - uwou yọ ẹgba ologbo nọ ma re ro ru udhedhẹ \\
  \midrule
	 Source:  &   We can even ask God to ‘ create in us a pure heart \\
	 Reference: &  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo \\
	 Prediction: & Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo \\ 
  \end{tabular}
\end{center}
\end{table}

\end{document}
